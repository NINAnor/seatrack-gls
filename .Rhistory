#Understanding drivers of auk mass mortality events in the North Sea and Skagerrak areas
####################
#1
loggerInfo<-getLoggerInfo()
loggerInfo<-loggerInfo[loggerInfo$deployment_species%in%c("Common guillemot"),]
loggerInfo1<-loggerInfo[loggerInfo$colony%in%c("Spannholmane"),]
loggerInfo<-
loggerInfo1
posdata_1<-getPosdata(species = NULL, colony = NULL, dataResponsible = NULL,
ringnumber = NULL, year = NULL, sessionId = loggerInfo$session_id,
individId = NULL, loadGeometries = F, loadImportDate = T,
asTibble = T, limit = F)
posdata_1<-as.data.frame(posdata_1)
posdata_1<-posdata_1[,c(2,5,6,7,8,9,10,11,12,13,14,15,31,32,16,17,20,21,25,27,33,34,35,37,38,39,40,41)]
names(posdata_1)[names(posdata_1) == 'software'] <- 'script_version'
names(posdata_1)[names(posdata_1) == 'eqfilter3'] <- 'eqfilter'
unique(posdata_1$colony)
names(posdata_1)[names(posdata_1) == 'lat_smooth2'] <- 'lat'
names(posdata_1)[names(posdata_1) == 'lon_smooth2'] <- 'lon'
posdata_1$analyzer[posdata_1$analyzer=="Vegard SandÃ¸y BrÃ¥then"]<-"Vegard Sandøy Bråthen"
setwd("P:/12393000_seatrack/Vegard/auk mass mortality")
saveRDS(posdata_1,file = paste("P:/12393000_seatrack/Vegard/auk mass mortality/seatrackGLS_Spannholmane_CG_October6th2025.rds",sep=""), ascii = FALSE, version = NULL,
compress = TRUE, refhook = NULL)
#act
act<-getRecordings(type = "activity",sessionId = loggerInfo$session_id,asTibble = T)
act
tail(act)
rm(list = ls())
Sys.setlocale(locale = 'en_BE.UTF-8')
########################
#Load packages
########################
# Packages
library(devtools)#install.packages("devtools")
library(sf) #install.packages('sf')
#devtools::install_github('NINAnor/seatrack-db/seatrackR',force = TRUE)
library(seatrackR)
library(lubridate)
#devtools::install_github("rstats-db/DBI",force=TRUE)
#devtools::install_github("rstats-db/RPostgres")
library(DBI)
library(dplyr)
source('C:/Users/vegard.brathen/Norsk Polarinstitutt/Benjamin Merkel - SEATRACK - shared/Database/Imports_Logger data/Std raw tables/Scripts/FUNCTIONS/FUNCTION_SEATRACK_datetime_conversion.r')
#source('/data/P-Prosjekter/12393000_seatrack/seatrackDB/Std_rawdata/Scripts/FUNCTIONS/FUNCTION_SEATRACK_datetime_conversion.r')
library(stringr)#install.packages("stringr")
connectSeatrack(Username = "testreader", Password = "testreader")
species<-"Common guillemot"
loggers<-getLoggerInfo(asTibble = T)
loggers<-loggers[loggers$deployment_species%in%species,]
loggers<-loggers[!is.na(loggers$download_type),]
########################
#select only data not already in db:
########################
data_in_db<-getRecordings(type = "activity",sessionId = loggers$session_id)
head(data_in_db)
#exclude loggers already present:
loggers<-loggers[!(loggers$session_id%in%unique(data_in_db$session_id)),]
View(loggers)
#add column matching the name of the raw data file:
loggers$filename<-paste(loggers$logger_serial_no,year(loggers$retrieval_date),loggers$logger_model,sep="_")
loggers$filename[loggers$producer%in%c("Migrate Technology")]<-paste0(loggers$filename[loggers$producer%in%c("Migrate Technology")],".deg")
loggers$filename[loggers$producer%in%c("Biotrack","BAS","Lotek")]<-paste0(loggers$filename[loggers$producer%in%c("Biotrack","BAS","Lotek")],".act")
all_loggers<-loggers
all_loggers
#save supporting data
support_dir<-'/data/P-Prosjekter/12393000_seatrack/seatrackDB/Std_rawdata/supporting_files/'
write.table(all_loggers,paste(support_dir,"activity_",species,"_sessions to import.txt",sep=""),quote=FALSE, col.names = TRUE,row.names=FALSE, sep="\t", append = FALSE)
########################
#set up directories
########################
#get data from:
dat.dir<-"C:/Users/vegard.brathen/Norsk Polarinstitutt/Benjamin Merkel - SEATRACK - shared/Database/Imports_Logger data/Raw logger data/ALL/"
#save data to:
save.dir<-"C:/Users/vegard.brathen/Norsk Polarinstitutt/Benjamin Merkel - SEATRACK - shared/Database/Imports_Logger data/Std raw tables/Outputs_to_import/"
###############################################################################
# Produce std activity files. First code for mk-loggers (Lotek/BAS/Biotrack) and then Migrate Tech
###############################################################################
###############################################################################
# BIOTRACK/BAS/Lotek
###############################################################################
loggers<-all_loggers[all_loggers$producer%in%c("Biotrack","BAS","Lotek"),]
files<-list.files(dat.dir)
files<-files[files%in%loggers$filename]
list_files<-paste(dat.dir,files,sep="")
list_files
list_of_final_files<-NULL
i=1
for(i in 1:length(list_files)){
tryCatch({
file<-read.table(list_files[i],sep=",",header=F, fill = T, skip = 1)
#remove if data has less than 5 rows
if(nrow(file) < 5){file<-NULL}
#mk7 rec activity in 3 sec intervals with a different column setup. This fixes that so it is recorded in 10 minutes intervals and in values 0-200
if(str_detect(list_files[i], c("mk3005"))|
str_detect(list_files[i], c("mk19"))|
str_detect(list_files[i], c("mk7"))|
ncol(file)%in%5){
act_bt2<-file[file$V5%in%"wet",]
act_bt2$V4<-as.numeric(act_bt2$V4)
act_bt2$V2 <- as.POSIXct(file$V2, format = "%d/%m/%y %H:%M:%S", tz = "GMT")
act_bt_test<- aggregate(V4 ~ cut(V2, breaks = "10 mins"), act_bt2, sum)
act_bt2<-as.data.frame(act_bt_test[,1])
act_bt2$V1<-'ok'
act_bt2$V3<-as.numeric(as_datetime(act_bt2[,1]))
act_bt2$V4<-as.numeric(act_bt_test[,2])
act_bt2<-act_bt2[,c(2,1,3,4)]
names(act_bt2) <- c("V1","V2","V3","V4")
act_bt2$V2<-as.vector(act_bt2$V2)
act_bt2$V2<-as.POSIXct(act_bt2$V2, tz="GMT")
library(dplyr)
ts <- seq.POSIXt(min(act_bt2$V2), max(act_bt2$V2), by="10 min")
df <- data.frame(timestamp=ts)
act_bt2$timestamp<-act_bt2$V2
act_bt2 <- full_join(df,act_bt2)
act_bt2$V2<-act_bt2$timestamp
act_bt2$timestamp<-NULL
act_bt2$V1<-"ok"
act_bt2$V3<-0
act_bt2$V5<-0
act_bt2$V4[is.na(act_bt2$V4)]<-0
act_bt2$V4<- act_bt2$V4/3/200
act_bt2$V6<-floor(act_bt2$V4)
act_bt2$V5[(act_bt2$V4*200)>200]<-200
act_bt2$V5[(act_bt2$V4*200)<201]<-act_bt2$V4[(act_bt2$V4*200)<201]*200
t=1
for(t in 1:length(act_bt2$V1)){
tryCatch({
if(act_bt2$V6[t]>0.99){act_bt2$V5[t:(t+(act_bt2$V6[t])-1)]<-200}
if(act_bt2$V6[t]>0.99){act_bt2$V5[(t+(act_bt2$V6[t]))]<-(act_bt2$V4[t]-floor(act_bt2$V4[t]))*200}
}, error=function(e){cat("ERROR :",conditionMessage(e), "\n")})
}
act_bt2$V4<-act_bt2$V5
act_bt2$V5<-NULL
act_bt2$V6<-NULL
file<-act_bt2
}
head(file)
file$V2 <- as.POSIXct(file$V2, format = "%d/%m/%y %H:%M:%S", tz = "GMT")
file$V5 <- as.Date(substr(file$V2,1,10))
#######################
#error check
#######################
##Error in immersion:
#remove NA's data from light
file<-file[!is.na(file$V4),]
#remove 'suspect' lines
file<-file[file$V1=="ok",]
#remove logger data that exceed maximum possible value of immersed
if(max(file$V4)>200) {file<-NULL}
#remove logger data that has only 0 values of immersion
#if(max(file$V4)==0) {file<-NULL}
#remove logger data that has negative values of immersion
if(min(file$V4)<0){file<-NULL}
##Error in date and time:
#remove if data holes exceed 3 months or difference in dates are negative
diff_time<-as.numeric(difftime(file$V2[2:length(file$V2)], file$V2[1:(length(file$V2)-1)], "GMT",units = c("mins")))
if(min(diff_time) < 0 | max(diff_time) > 129600 ) file<-NULL
#######################
# limit data to dep&ret/shutdown_date
######################
#find limiting dates from database
limiting_dates<-loggers[loggers$filename%in%files[i],]
#limit to deployment date
file<-file[file$V5>na.omit(limiting_dates$deployment_date),]
#limit to retrieval date
file<-file[file$V5<na.omit(limiting_dates$retrieval_date),]
#add session_id
file$V6<-na.omit(limiting_dates$session_id)
#######################
# rename and rearrange columns
#######################
file_final<-NULL
file_final<-as.data.frame(file$V6)
colnames(file_final)<-"session_id"
file_final$filename<-limiting_dates$filename
file_final$individ_id<-limiting_dates$individ_id
file_final$date_time<-as.character(file$V2)
file_final$conductivity<-as.character(file$V4)
file_final$std_conductivity<-as.character(file$V4/200)
list_of_final_files[[i]]<-as.data.frame(file_final)
}, error=function(e){cat("ERROR :",conditionMessage(e), "\n")})
}
all_data = do.call(rbind, list_of_final_files)
all_data$filename<-as.character(all_data$filename)
unique(all_data$filename)
list_of_final_files
list_files
list_files[i]
file
act_bt2
i=1
file<-read.table(list_files[i],sep=",",header=F, fill = T, skip = 1)
file
#remove if data has less than 5 rows
if(nrow(file) < 5){file<-NULL}
file
list_of_final_files[[i]]
list_of_final_files
as.data.frame(file_final)
list_of_final_files<-as.data.frame(NA)
list_of_final_files
colnames(file_final)<-"session_id"
list_of_final_files<-as.data.frame(NA)
colnames(list_of_final_files)<-"session_id"
list_of_final_files$filename<-NA
list_of_final_files$individ_id<-NA
list_of_final_files$date_time<-NA
list_of_final_files$conductivity<-NA
list_of_final_files$std_conductivity<-NA
list_of_final_files
i=1
for(i in 1:length(list_files)){
tryCatch({
file<-read.table(list_files[i],sep=",",header=F, fill = T, skip = 1)
#remove if data has less than 5 rows
if(nrow(file) < 5){file<-NULL}
#mk7 rec activity in 3 sec intervals with a different column setup. This fixes that so it is recorded in 10 minutes intervals and in values 0-200
if(str_detect(list_files[i], c("mk3005"))|
str_detect(list_files[i], c("mk19"))|
str_detect(list_files[i], c("mk7"))|
ncol(file)%in%5){
act_bt2<-file[file$V5%in%"wet",]
act_bt2$V4<-as.numeric(act_bt2$V4)
act_bt2$V2 <- as.POSIXct(file$V2, format = "%d/%m/%y %H:%M:%S", tz = "GMT")
act_bt_test<- aggregate(V4 ~ cut(V2, breaks = "10 mins"), act_bt2, sum)
act_bt2<-as.data.frame(act_bt_test[,1])
act_bt2$V1<-'ok'
act_bt2$V3<-as.numeric(as_datetime(act_bt2[,1]))
act_bt2$V4<-as.numeric(act_bt_test[,2])
act_bt2<-act_bt2[,c(2,1,3,4)]
names(act_bt2) <- c("V1","V2","V3","V4")
act_bt2$V2<-as.vector(act_bt2$V2)
act_bt2$V2<-as.POSIXct(act_bt2$V2, tz="GMT")
library(dplyr)
ts <- seq.POSIXt(min(act_bt2$V2), max(act_bt2$V2), by="10 min")
df <- data.frame(timestamp=ts)
act_bt2$timestamp<-act_bt2$V2
act_bt2 <- full_join(df,act_bt2)
act_bt2$V2<-act_bt2$timestamp
act_bt2$timestamp<-NULL
act_bt2$V1<-"ok"
act_bt2$V3<-0
act_bt2$V5<-0
act_bt2$V4[is.na(act_bt2$V4)]<-0
act_bt2$V4<- act_bt2$V4/3/200
act_bt2$V6<-floor(act_bt2$V4)
act_bt2$V5[(act_bt2$V4*200)>200]<-200
act_bt2$V5[(act_bt2$V4*200)<201]<-act_bt2$V4[(act_bt2$V4*200)<201]*200
t=1
for(t in 1:length(act_bt2$V1)){
tryCatch({
if(act_bt2$V6[t]>0.99){act_bt2$V5[t:(t+(act_bt2$V6[t])-1)]<-200}
if(act_bt2$V6[t]>0.99){act_bt2$V5[(t+(act_bt2$V6[t]))]<-(act_bt2$V4[t]-floor(act_bt2$V4[t]))*200}
}, error=function(e){cat("ERROR :",conditionMessage(e), "\n")})
}
act_bt2$V4<-act_bt2$V5
act_bt2$V5<-NULL
act_bt2$V6<-NULL
file<-act_bt2
}
head(file)
file$V2 <- as.POSIXct(file$V2, format = "%d/%m/%y %H:%M:%S", tz = "GMT")
file$V5 <- as.Date(substr(file$V2,1,10))
#######################
#error check
#######################
##Error in immersion:
#remove NA's data from light
file<-file[!is.na(file$V4),]
#remove 'suspect' lines
file<-file[file$V1=="ok",]
#remove logger data that exceed maximum possible value of immersed
if(max(file$V4)>200) {file<-NULL}
#remove logger data that has only 0 values of immersion
#if(max(file$V4)==0) {file<-NULL}
#remove logger data that has negative values of immersion
if(min(file$V4)<0){file<-NULL}
##Error in date and time:
#remove if data holes exceed 3 months or difference in dates are negative
diff_time<-as.numeric(difftime(file$V2[2:length(file$V2)], file$V2[1:(length(file$V2)-1)], "GMT",units = c("mins")))
if(min(diff_time) < 0 | max(diff_time) > 129600 ) file<-NULL
#######################
# limit data to dep&ret/shutdown_date
######################
#find limiting dates from database
limiting_dates<-loggers[loggers$filename%in%files[i],]
#limit to deployment date
file<-file[file$V5>na.omit(limiting_dates$deployment_date),]
#limit to retrieval date
file<-file[file$V5<na.omit(limiting_dates$retrieval_date),]
#add session_id
file$V6<-na.omit(limiting_dates$session_id)
#######################
# rename and rearrange columns
#######################
file_final<-NULL
file_final<-as.data.frame(file$V6)
colnames(file_final)<-"session_id"
file_final$filename<-limiting_dates$filename
file_final$individ_id<-limiting_dates$individ_id
file_final$date_time<-as.character(file$V2)
file_final$conductivity<-as.character(file$V4)
file_final$std_conductivity<-as.character(file$V4/200)
list_of_final_files[[i]]<-as.data.frame(file_final)
}, error=function(e){cat("ERROR :",conditionMessage(e), "\n")})
}
list_of_final_files
colony<-"Spannholmane"
loggers<-getLoggerInfo(asTibble = T)
loggers<-loggers[loggers$deployment_species%in%species & loggers$colony%in%colony,]
loggers<-loggers[loggers$deployment_species%in%species,]
loggers<-loggers[!is.na(loggers$download_type),]
loggers
View(loggers)
loggers<-getLoggerInfo(asTibble = T)
loggers<-loggers[loggers$deployment_species%in%species & loggers$colony%in%colony,]
loggers<-loggers[loggers$deployment_species%in%species,]
loggers<-loggers[!is.na(loggers$download_type),]
########################
#select only data not already in db:
########################
data_in_db<-getRecordings(type = "activity",sessionId = loggers$session_id)
head(data_in_db)
#exclude loggers already present:
loggers<-loggers[!(loggers$session_id%in%unique(data_in_db$session_id)),]
View(loggers)
#add column matching the name of the raw data file:
loggers$filename<-paste(loggers$logger_serial_no,year(loggers$retrieval_date),loggers$logger_model,sep="_")
loggers$filename[loggers$producer%in%c("Migrate Technology")]<-paste0(loggers$filename[loggers$producer%in%c("Migrate Technology")],".deg")
loggers$filename[loggers$producer%in%c("Biotrack","BAS","Lotek")]<-paste0(loggers$filename[loggers$producer%in%c("Biotrack","BAS","Lotek")],".act")
all_loggers<-loggers
all_loggers
#save supporting data
support_dir<-'/data/P-Prosjekter/12393000_seatrack/seatrackDB/Std_rawdata/supporting_files/'
write.table(all_loggers,paste(support_dir,"activity_",species,"_sessions to import.txt",sep=""),quote=FALSE, col.names = TRUE,row.names=FALSE, sep="\t", append = FALSE)
########################
#set up directories
########################
#get data from:
dat.dir<-"C:/Users/vegard.brathen/Norsk Polarinstitutt/Benjamin Merkel - SEATRACK - shared/Database/Imports_Logger data/Raw logger data/ALL/"
#save data to:
save.dir<-"C:/Users/vegard.brathen/Norsk Polarinstitutt/Benjamin Merkel - SEATRACK - shared/Database/Imports_Logger data/Std raw tables/Outputs_to_import/"
###############################################################################
# Produce std activity files. First code for mk-loggers (Lotek/BAS/Biotrack) and then Migrate Tech
###############################################################################
###############################################################################
# BIOTRACK/BAS/Lotek
###############################################################################
loggers<-all_loggers[all_loggers$producer%in%c("Biotrack","BAS","Lotek"),]
files<-list.files(dat.dir)
files<-files[files%in%loggers$filename]
list_files<-paste(dat.dir,files,sep="")
list_files
list_of_final_files<-NULL
list_files
loggers
paste(loggers$logger_serial_no,year(loggers$retrieval_date),loggers$logger_model,sep="_")
#add column matching the name of the raw data file:
loggers$filename<-paste(loggers$logger_serial_no,year(loggers$retrieval_date),loggers$logger_model,sep="_")
loggers$filename[loggers$producer%in%c("Migrate Technology")]<-paste0(loggers$filename[loggers$producer%in%c("Migrate Technology")],".deg")
loggers$filename[loggers$producer%in%c("Biotrack","BAS","Lotek")]<-paste0(loggers$filename[loggers$producer%in%c("Biotrack","BAS","Lotek")],".act")
all_loggers<-loggers
all_loggers
########################
#set up directories
########################
#get data from:
dat.dir<-"C:/Users/vegard.brathen/Norsk Polarinstitutt/Benjamin Merkel - SEATRACK - shared/Database/Imports_Logger data/Raw logger data/ALL/"
#save data to:
save.dir<-"C:/Users/vegard.brathen/Norsk Polarinstitutt/Benjamin Merkel - SEATRACK - shared/Database/Imports_Logger data/Std raw tables/Outputs_to_import/"
###############################################################################
# Produce std activity files. First code for mk-loggers (Lotek/BAS/Biotrack) and then Migrate Tech
###############################################################################
###############################################################################
# BIOTRACK/BAS/Lotek
###############################################################################
loggers<-all_loggers[all_loggers$producer%in%c("Biotrack","BAS","Lotek"),]
loggers
files<-list.files(dat.dir)
files<-files[files%in%loggers$filename]
files
loggers
#save.dir<-"/data/P-Prosjekter/12393000_seatrack/seatrackDB/Std_rawdata/Import to db/std_activity/"
View(loggers)
View(loggers)
View(all_loggers)
colony<-"Spannholmane"
loggers<-getLoggerInfo(asTibble = T)
loggers<-loggers[loggers$deployment_species%in%species & loggers$colony%in%colony,]
loggers<-loggers[loggers$deployment_species%in%species,]
loggers<-loggers[!is.na(loggers$download_type),]
########################
#select only data not already in db:
########################
data_in_db<-getRecordings(type = "activity",sessionId = loggers$session_id)
head(data_in_db)
#exclude loggers already present:
loggers<-loggers[!(loggers$session_id%in%unique(data_in_db$session_id)),]
View(loggers)
########################
#select only data not already in db:
########################
data_in_db<-getRecordings(type = "activity",sessionId = loggers$session_id)
tail(data_in_db)
########################
#select only data not already in db:
########################
data_in_db<-getRecordings(type = "activity",sessionId = loggers$session_id)
tail(data_in_db)
colony<-"Spannholmane"
loggers<-getLoggerInfo(asTibble = T)
loggers<-loggers[loggers$deployment_species%in%species & loggers$colony%in%colony,]
loggers<-loggers[loggers$deployment_species%in%species,]
loggers<-loggers[!is.na(loggers$download_type),]
########################
#select only data not already in db:
########################
data_in_db<-getRecordings(type = "activity",sessionId = loggers$session_id)
tail(data_in_db)
View(data_in_db)
#act
act<-getRecordings(type = "activity",sessionId = loggerInfo$session_id,asTibble = T)
act<-as.data.frame(act)
#act
act<-getRecordings(type = "activity",sessionId = loggerInfo$session_id,asTibble = T)
####################
#Understanding drivers of auk mass mortality events in the North Sea and Skagerrak areas
####################
#1
loggerInfo<-getLoggerInfo()
loggerInfo<-loggerInfo[loggerInfo$deployment_species%in%c("Common guillemot"),]
loggerInfo1<-loggerInfo[loggerInfo$colony%in%c("Spannholmane"),]
loggerInfo<-loggerInfo[loggerInfo$colony%in%c("Spannholmane"),]
posdata_1<-getPosdata(species = NULL, colony = NULL, dataResponsible = NULL,
ringnumber = NULL, year = NULL, sessionId = loggerInfo$session_id,
individId = NULL, loadGeometries = F, loadImportDate = T,
asTibble = T, limit = F)
posdata_1<-as.data.frame(posdata_1)
posdata_1<-posdata_1[,c(2,5,6,7,8,9,10,11,12,13,14,15,31,32,16,17,20,21,25,27,33,34,35,37,38,39,40,41)]
names(posdata_1)[names(posdata_1) == 'software'] <- 'script_version'
names(posdata_1)[names(posdata_1) == 'eqfilter3'] <- 'eqfilter'
unique(posdata_1$colony)
names(posdata_1)[names(posdata_1) == 'lat_smooth2'] <- 'lat'
names(posdata_1)[names(posdata_1) == 'lon_smooth2'] <- 'lon'
posdata_1$analyzer[posdata_1$analyzer=="Vegard SandÃ¸y BrÃ¥then"]<-"Vegard Sandøy Bråthen"
saveRDS(posdata_1,file = paste("P:/12393000_seatrack/Vegard/auk mass mortality/seatrackGLS_Spannholmane_CG_October6th2025.rds",sep=""), ascii = FALSE, version = NULL,
compress = TRUE, refhook = NULL)
#act
act<-getRecordings(type = "activity",sessionId = loggerInfo$session_id,asTibble = T)
act<-as.data.frame(act)
tail(act)
View(act)
#act
act<-getRecordings(type = "activity",sessionId = loggerInfo$session_id,asTibble = T)
act<-as.data.frame(act)
head(act)
saveRDS(act,file = paste(string_dir,"immersion_SEATRACK_Spannholmane_CG_October6th2025.rds",sep=""), ascii = FALSE, version = NULL,
compress = TRUE, refhook = NULL)
#light
light<-getRecordings(type = "light",sessionId = loggerInfo$session_id,asTibble = T)
light<-as.data.frame(light)
saveRDS(light,file = paste(string_dir,"light_SEATRACK_Spannholmane_CG_October6th2025.rds",sep=""), ascii = FALSE, version = NULL,
compress = TRUE, refhook = NULL)
#temperature
temperature<-getRecordings(type = "temperature",sessionId = loggerInfo$session_id,asTibble = T)
temperature<-as.data.frame(temperature)
saveRDS(temperature,file = paste(string_dir,"temperature_SEATRACK_Spannholmane_CG_October6th2025.rds",sep=""), ascii = FALSE, version = NULL,
compress = TRUE, refhook = NULL)
string_dir<-"P:/12393000_seatrack/Vegard/auk mass mortality/"
#act
act<-getRecordings(type = "activity",sessionId = loggerInfo$session_id,asTibble = T)
act<-as.data.frame(act)
head(act)
saveRDS(act,file = paste(string_dir,"immersion_SEATRACK_Spannholmane_CG_October6th2025.rds",sep=""), ascii = FALSE, version = NULL,
compress = TRUE, refhook = NULL)
#light
light<-getRecordings(type = "light",sessionId = loggerInfo$session_id,asTibble = T)
light<-as.data.frame(light)
saveRDS(light,file = paste(string_dir,"light_SEATRACK_Spannholmane_CG_October6th2025.rds",sep=""), ascii = FALSE, version = NULL,
compress = TRUE, refhook = NULL)
#temperature
temperature<-getRecordings(type = "temperature",sessionId = loggerInfo$session_id,asTibble = T)
temperature<-as.data.frame(temperature)
saveRDS(temperature,file = paste(string_dir,"temperature_SEATRACK_Spannholmane_CG_October6th2025.rds",sep=""), ascii = FALSE, version = NULL,
compress = TRUE, refhook = NULL)
plot(temperature$wet_temp_mean~temperature$date_time)
saveRDS(loggerInfo,file = paste(string_dir,"SEATRACK_loggerInfo_Spannholmane_CG_October6th2025.rds",sep=""), ascii = FALSE, version = NULL,
compress = TRUE, refhook = NULL)
posdata_1<-getPosdata(species = "Leach's storm petrel", colony = NULL, dataResponsible = NULL,
ringnumber = NULL, year = NULL, sessionId = NULL,
individId = NULL, loadGeometries = F, loadImportDate = T,
asTibble = T, limit = F)
View(posdata_1)
connectSeatrack(Username = "vegard_braathen", Password = "vegard_braathen")
updatePosdataSession()
posdata_1<-getPosdata(species = "Leach's storm petrel", colony = NULL, dataResponsible = NULL,
ringnumber = NULL, year = NULL, sessionId = NULL,
individId = NULL, loadGeometries = F, loadImportDate = T,
asTibble = T, limit = F)
View(posdata_1)
updatePosdataSession()
connectSeatrack(Username = "vegard_braathen", Password = "vegard_braathen")
updatePosdataSession()
connectSeatrack(Username = "vegard_braathen", Password = "vegard_braathen")
connectSeatrack(Username = "vegard_braathen", Password = "vegard_braathen")
updatePosdataSession()
posdata_1<-getPosdata(species = "Leach's storm petrel", colony = NULL, dataResponsible = NULL,
ringnumber = NULL, year = NULL, sessionId = NULL,
individId = NULL, loadGeometries = F, loadImportDate = T,
asTibble = T, limit = F)
View(posdata_1)
updateViews()
